# .env.example for AI Orchestrator
# This file contains all environment variables required by the AI Orchestrator service

# Server Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info
WORKERS=4

# AI Model Configuration
DEFAULT_LLM_MODEL=gpt-4o
DEFAULT_VISION_MODEL=gpt-4-vision
DEFAULT_EMBEDDING_MODEL=text-embedding-3-large

# API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here
COHERE_API_KEY=your_cohere_api_key_here

# Model Endpoints
OPENAI_API_BASE=https://api.openai.com/v1
ANTHROPIC_API_BASE=https://api.anthropic.com
MISTRAL_API_BASE=https://api.mistral.ai/v1
COHERE_API_BASE=https://api.cohere.ai/v1

# Local Models
ENABLE_LOCAL_MODELS=false
LOCAL_MODELS_PATH=./models
LOCAL_MODELS_DEVICE=cuda

# Rate Limiting
RATE_LIMIT_TOKENS_PER_MINUTE=100000
RATE_LIMIT_REQUESTS_PER_MINUTE=300

# Security
AUTH_TOKEN=your_auth_token_here
ALLOWED_ORIGINS=http://localhost:3000,https://alt-las.example.com

# Monitoring and Telemetry
ENABLE_TELEMETRY=true
TELEMETRY_ENDPOINT=http://telemetry-service:4318
